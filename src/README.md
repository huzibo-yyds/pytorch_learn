



# 22_nn_sequential

ä»¿ç…§CIFAR 10 Modelï¼Œæ„é€ ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚

![Structure-of-CIFAR10-quick-model](img/Structure-of-CIFAR10-quick-model.png)



å¦‚ä½•ç¡®å®šå·ç§¯å±‚paddingå‚æ•°

![shape-of-conv2d](img/shape-of-conv2d.png)





# 23_loss

æŸå¤±å‡½æ•°ï¼Œç®€è¨€ä¹‹ï¼Œè®¡ç®—é¢„æµ‹ç»“æœä¸å®é™…æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚











# 25

UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use '**<u>weights</u>**' instead.
  warnings.warn

UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)





VGG16 æ¨¡å‹

```
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
```



# 26_save_load

å°†æ¨¡å‹ï¼ˆç½‘ç»œæ¨¡å‹ï¼‰ä¿å­˜ï¼ŒåŠ è½½



1. ã€æ–¹å¼1ã€‘ç›´æ¥ä¿å­˜æ¨¡å‹ç»“æ„+æ¨¡å‹å‚æ•°
   ```python
   torch.save(vgg16, "./model/vgg16_model1")
   
   model1 = torch.load("./model/vgg16_model1")
   ```

   
2. ã€æ–¹å¼2ã€‘åªä¿å­˜æ¨¡å‹å‚æ•°ï¼ˆå®˜æ–¹æ¨èï¼‰
   ```python
   torch.save(vgg16.state_dict(), "./model/vgg16_model2")
   
   model2 = torchvision.models.vgg16(weights=None)
   model2.load_state_dict(torch.load("./model/vgg16_model2"))
   ```

   

ğŸ”ºæ³¨æ„ï¼Œè‡ªå·±çš„æ¨¡å‹ä½¿ç”¨æ–¹å¼2ä¿å­˜åã€‚è‹¥è¦loadï¼Œéœ€è¦åœ¨loadå‰å°†æ¨¡å‹å¯¼å…¥ã€‚





# 27 train

å®Œæ•´çš„æ¨¡å‹è®­ç»ƒè¿‡ç¨‹



è®­ç»ƒè¿‡ç¨‹çš„åŸºæœ¬æµç¨‹

```python
# å‰å‘ä¼ æ’­
output = model(input_tensor)

# è®¡ç®—æŸå¤±
loss = criterion(output, target)

# åå‘ä¼ æ’­
optimizer.zero_grad()  # å°†æ¢¯åº¦å½’é›¶
loss.backward()  # è®¡ç®—æ¢¯åº¦

# å‚æ•°æ›´æ–°
optimizer.step()
```



### å‚æ•°ä¸æ¢¯åº¦

**å‚æ•°ï¼ˆParametersï¼‰**

+ æ¨¡å‹ä¸­éœ€è¦è¢«å­¦ä¹ çš„å¯è°ƒæ•´çš„**<u>æƒé‡å’Œåç½®</u>**ã€‚
+ è¿™äº›å‚æ•°æ§åˆ¶ç€æ¨¡å‹çš„è¡Œä¸ºï¼Œé€šè¿‡è°ƒæ•´å®ƒä»¬ï¼Œå¯ä»¥ä½¿æ¨¡å‹é€‚åº”è¾“å…¥æ•°æ®å¹¶äº§ç”Ÿæ­£ç¡®çš„è¾“å‡º
+ åœ¨ PyTorch ä¸­ï¼Œæ¨¡å‹çš„å‚æ•°é€šå¸¸ç”± `torch.nn.Parameter` ç±»æ¥è¡¨ç¤ºï¼Œå®ƒæ˜¯ `torch.Tensor` çš„å­ç±»ï¼Œå¯ä»¥é€šè¿‡ `model.parameters()` æ–¹æ³•è®¿é—®ã€‚



**æ¢¯åº¦ï¼ˆGradientsï¼‰**

+ æ¢¯åº¦æ˜¯<u>æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°çš„å¯¼æ•°</u>ï¼Œå®ƒè¡¨ç¤ºäº†æŸå¤±å‡½æ•°åœ¨å‚æ•°ç©ºé—´ä¸­çš„**<u>å˜åŒ–ç‡</u>**ã€‚
+ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦å‘Šè¯‰æˆ‘ä»¬åœ¨å½“å‰å‚æ•°å€¼ä¸‹ï¼Œå¦‚æœå¾®è°ƒå‚æ•°ï¼Œå¯ä»¥ä½¿æŸå¤±å‡½æ•°ä¸‹é™çš„æ–¹å‘ã€‚
+ åœ¨ PyTorch ä¸­ï¼Œæ¢¯åº¦é€šå¸¸ä¸å‚æ•°ç»‘å®šåœ¨ä¸€èµ·ï¼Œå³æ¯ä¸ªå‚æ•°å¼ é‡éƒ½æœ‰ä¸€ä¸ªä¸ä¹‹å¯¹åº”çš„æ¢¯åº¦å¼ é‡ï¼Œå¯ä»¥é€šè¿‡ `parameter.grad` å±æ€§è®¿é—®ã€‚



å‚æ•°æ›´æ–°ï¼Œå°±æ˜¯æ ¹æ®æ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œè°ƒæ•´ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚





â“ä¸ºä»€ä¹ˆæ¯æ¬¡è®­ç»ƒå¼€å§‹éƒ½éœ€è¦æ¢¯åº¦å½’é›¶

 PyTorch ä¸­çš„æ¢¯åº¦æ˜¯<u>ç´¯ç§¯</u>çš„ã€‚è¿™æ„å‘³ç€æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¼šè¢«ç´¯åŠ ï¼Œè€Œä¸æ˜¯è¢«è¦†ç›–ã€‚å› æ­¤ï¼Œåœ¨æ¯æ¬¡è®­ç»ƒå¼€å§‹ä¹‹å‰ï¼Œéœ€è¦æ˜¾å¼åœ°å°†æ¢¯åº¦å½’é›¶ï¼Œä»¥ç¡®ä¿æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦éƒ½æ˜¯å½“å‰æ‰¹æ¬¡æ•°æ®è®¡ç®—å¾—åˆ°çš„ï¼Œè€Œä¸æ˜¯ä¹‹å‰æ‰€æœ‰æ‰¹æ¬¡æ•°æ®çš„ç´¯ç§¯ç»“æœ



### è®­ç»ƒè¿‡ç¨‹

1. å‡†å¤‡æ•°æ®é›†
2. å‡†å¤‡DataLoader
3. åˆ›å»ºç½‘ç»œæ¨¡å‹
4. æŸå¤±å‡½æ•°
5. ä¼˜åŒ–å™¨
6. é¢„å¤„ç†-è®¾ç½®è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸€äº›å‚æ•°
7. è®­ç»ƒ
   1. å–æ•°æ®
   2. å‰å‘ä¼ æ’­è®¡ç®—
   3. è®¡ç®—loss
   4. åå‘ä¼ æ’­
   5. æ›´æ–°å‚æ•°-ä¼˜åŒ–
8. æµ‹è¯•
9. åå¤„ç†-ï¼ˆä¿å­˜æ¨¡å‹|è¾“å‡ºå±•ç¤ºä¿¡æ¯ï¼‰



# 30 train_gpu





æ–¹å¼1ï¼Œåœ¨ä»¥ä¸‹ä½ç½®åŠ ä¸Š `.cuda()`

![image-20240306160501046](img/image-20240306160501046.png)



æ–¹å¼2ï¼Œ`.to(device)`









# 32 å®Œæ•´çš„æ¨¡å‹éªŒè¯è¿‡ç¨‹



1. é¢„å¤„ç†ï¼Œå°†æ•°æ®è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥æ ¼å¼
2. åŠ è½½æ¨¡å‹è¿›è¡Œé¢„æµ‹





